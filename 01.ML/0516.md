## 과대적합, 과소적합, 일반화

### 과대적합(Overfitting)
- 모델이 훈련 데이터에 너무 학습을 많이해서 실제 데이터에 대해서는 성능이 나빠지는 것

### 과소적합(Underfitting)
- 모델이 훈련 데이터에 너무 학습을 하지 않아서 실제 데이터에 대해서는 성능이 나빠지는 것

## Decision Tree (결정 트리 모델) -> Classification(분류) 모델
- 의사 결정 방향 : 불순도가 낮아지는 방향
- 장점 : 쉽고 직관적
- 단점 : 과대적합이 발생하기 쉬움 -> 극복하기 위해 사전에 트리의 크기를 결정해야 함

## Linear Regression (선형 회귀 모델)
- **연속적인 실수 값**을 예측하는 분야
- **직선의 형태**를 가지는 1차식으로 **연속적인 실수 값**을 예측하는 모델

### Regression의 중요성 및 필요성
- **딥러닝 이론의 기초**
- **현업에서 많이 사용**되며 활용도가 높음
- ex. 통계 자료 예측, 기상 예측, 주가 예측 등

### 선형 회귀란?
- 학습 데이터에는 없는 미지의 데이터에 대한 값을 예측할 때,
- 데이터의 분포를 가장 잘 표현할 수 잇는 **직선(y = wx + b)**을 그려서 예측하는 방법

### 단일 선형 회귀
- y = wx + b
- y : 종속 변수
- w : weight(가중치)
- x : 독립 변수
- b : bias(절편, 편향)

### 다중 선형 회귀
- y = w1x1 + w2x2 + w3x3 + ... + wnxn + b
- 모델 w 파라미터 : model.coef_
- 모델 b 파라미터 : model.intercept_

### 회귀 모델 평가 지표
- cf. 분류 모델 평가 지표 : accuracy(정확도)
- 회귀 모델의 대표적인 평가 지표 : MSE(Mean Squared Error), RMSE(Root Mean Squared Error)
- 오차 : 예측값 - 정답값

### MSE가 최소가 되는 w, b를 찾는 방법
- 1. 수학공식을 이용한 해석적 방법
- 2. 경사 하강법(Gradient Descent Algorithm)

### 경사하강법(Gradient Descent Algorithm)
- SDGRegressor
- 점진적으로 오차가 작은 선형함수를 찾아가는 방법
- 오차를 수정하는 방향으로 그래프를 다시 그려줌
- 선형함수를 잘못 찾았을 경우 수정이 가능
- 점진적으로 찾아가므로 계산량이 많아 시간이 오래걸림